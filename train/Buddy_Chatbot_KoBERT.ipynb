{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Buddy-Chatbot_KoBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdSPfnyOwqF_"
      },
      "source": [
        "* KoBERT install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJeI_zH3oOjF",
        "outputId": "10df6df6-6e59-4de7-aee4-7c2943624786"
      },
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-fy1ijkhk\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-fy1ijkhk\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12718 sha256=8a9a5c77502bc1434b1f1732dc33ee2c7314bb3b5075f0dcf1ab583664f9ecaa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-asdg3jyq/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n",
            "Successfully built kobert\n",
            "Installing collected packages: kobert\n",
            "Successfully installed kobert-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhIDsIdrq8cG"
      },
      "source": [
        "* Google Drive 연동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BUSgW2UohaE",
        "outputId": "1aca0a01-bf67-4a1b-9fe2-ead56172cc47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUBc6vbo8Y_0"
      },
      "source": [
        "* https://github.com/School-is-hard/buddy_KoBERT.git 를 통해 git clone 가능\n",
        "* 해당 페이지는 이미 구글 드라이브에 폴더가 형성되어 있으므로 넘어갔다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwqip0vKq_CE"
      },
      "source": [
        "* Package 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaaiNivFohdL",
        "outputId": "76bb67f4-f1eb-41b8-bf0e-4d16533637ba"
      },
      "source": [
        "!pip install -r /content/drive/'My Drive'/'Colab Notebooks'/buddy/requirements.txt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kobert-transformers==0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/6d/f4e21513c1f26cacd68c144a428ccaa90dd92d85985e878976ebbaf06624/kobert_transformers-0.4.1-py3-none-any.whl\n",
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (1.8.1+cu101)\n",
            "Collecting tokenizers==0.8.1rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 7.9MB/s \n",
            "\u001b[?25hCollecting kss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/ea/3030770642a58a08777dfa324a1b65a2f53f1574de8dd84424851f0c2ec7/kss-2.5.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 6)) (1.1.4)\n",
            "Collecting flask_restful\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/02/7e21a73564fe0d9d1a3a4ff478dfc407815c4e2fa4e5121bcfc646ba5d15/Flask_RESTful-0.3.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (20.9)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 16.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 18.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 3)) (3.7.4.3)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 6)) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from flask_restful->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask_restful->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 7)) (2018.9)\n",
            "Collecting aniso8601>=0.82\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/04/e97c12dc034791d7b504860acfcdd2963fa21ae61eaca1c9d31245f812c3/aniso8601-9.0.1-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->-r /content/drive/My Drive/Colab Notebooks/buddy/requirements.txt (line 6)) (2.0.1)\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers, kobert-transformers, kss, aniso8601, flask-restful\n",
            "Successfully installed aniso8601-9.0.1 flask-restful-0.3.9 kobert-transformers-0.4.1 kss-2.5.1 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGBCSsXlrIHF"
      },
      "source": [
        "* Path 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fkt3nu6ohfu"
      },
      "source": [
        "import sys\n",
        "sys.path.append('drive/My Drive/Colab Notebooks/')\n",
        "sys.path.append('drive/My Drive/Colab Notebooks/buddy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAOg1RPyP2vT"
      },
      "source": [
        "* import Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCygHnQYo-Ms"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from transformers import AdamW\n",
        "from torch.utils.data import dataloader\n",
        "from buddy.dataloader.wellness import WellnessTextClassificationDataset\n",
        "from buddy.model.kobert import KoBERTforSequenceClassfication"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJJGa4hMo-Px",
        "outputId": "9fa20098-4fc3-4142-9726-a922cb94f5be"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zod8mSDq8s8d"
      },
      "source": [
        "* 사전에 데이터 전처리 필요\n",
        "  * preprocess 폴더의 training_data 속 함수를 이용해 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSkHcZoRrNOc"
      },
      "source": [
        "* Train 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFIW-GpLrPSd"
      },
      "source": [
        "def train(device, epoch, model, optimizer, train_loader, save_step, save_ckpt_path, train_step = 0):\n",
        "    losses = []\n",
        "    train_start_index = train_step+1 if train_step != 0 else 0\n",
        "    total_train_step = len(train_loader)\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total= total_train_step, desc=f\"Train({epoch})\") as pbar:\n",
        "        pbar.update(train_step)\n",
        "        for i, data in enumerate(train_loader, train_start_index):\n",
        "          \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(**data)\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss.item():.3f} ({np.mean(losses):.3f})\")\n",
        "\n",
        "            if i >= total_train_step or i % save_step == 0:\n",
        "                torch.save({\n",
        "                    'epoch': epoch,  # 현재 학습 epoch\n",
        "                    'model_state_dict': model.state_dict(),  # 모델 저장\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 저장\n",
        "                    'loss': loss.item(),  # Loss 저장\n",
        "                    'train_step': i,  # 현재 진행한 학습\n",
        "                    'total_train_step': len(train_loader)  # 현재 epoch에 학습 할 총 train step\n",
        "                }, save_ckpt_path)\n",
        "\n",
        "    return np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnE1Aa3HP-rb"
      },
      "source": [
        "* Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_ShdSNi3KWv"
      },
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8a5cz87Grc9O",
        "outputId": "bd1fd61b-a6c8-4b66-9a01-a75cb7efdb88"
      },
      "source": [
        "root_path = \"/content/drive/MyDrive/Colab Notebooks/buddy\"\n",
        "data_path = f\"{root_path}/data/wellness_dialog_for_text_classification_train.txt\"\n",
        "checkpoint_path =f\"{root_path}/checkpoint\"\n",
        "save_ckpt_path = f\"{checkpoint_path}/kobert-wellnesee-text-classification.pth\"\n",
        "\n",
        "n_epoch = 50 #Num of Epoch\n",
        "batch_size = 4 #배치 사이즈\n",
        "ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(ctx)\n",
        "save_step = 100 #학습 저장 주기\n",
        "learning_rate = 5e-6  #Learning Rate\n",
        "\n",
        "#WellnessTextClassificationDataset Data Loader\n",
        "dataset = WellnessTextClassificationDataset(file_path=data_path, device=device)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = KoBERTforSequenceClassfication()\n",
        "model.to(device)\n",
        "\n",
        "#Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "\n",
        "pre_epoch, pre_loss, train_step = 0, 0, 0\n",
        "if os.path.isfile(save_ckpt_path):\n",
        "    checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
        "    pre_epoch = checkpoint['epoch']\n",
        "    train_step =  checkpoint['train_step']\n",
        "    total_train_step =  checkpoint['total_train_step']\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    print(f\"load pretrain from: {save_ckpt_path}, epoch={pre_epoch}\")\n",
        "\n",
        "losses = []\n",
        "offset = pre_epoch\n",
        "for step in range(n_epoch):\n",
        "    epoch = step + offset\n",
        "    loss = train(device, epoch, model, optimizer, train_loader, save_step, save_ckpt_path, train_step)\n",
        "    losses.append(loss)\n",
        "\n",
        "# data\n",
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train(0): 100%|██████████| 1179/1179 [03:40<00:00,  5.34it/s, Loss: 5.683 (5.583)]\n",
            "Train(1): 100%|██████████| 1179/1179 [03:40<00:00,  5.34it/s, Loss: 6.687 (5.478)]\n",
            "Train(2): 100%|██████████| 1179/1179 [03:39<00:00,  5.38it/s, Loss: 5.460 (5.407)]\n",
            "Train(3): 100%|██████████| 1179/1179 [03:42<00:00,  5.30it/s, Loss: 1.944 (5.249)]\n",
            "Train(4): 100%|██████████| 1179/1179 [03:44<00:00,  5.26it/s, Loss: 5.841 (5.013)]\n",
            "Train(5): 100%|██████████| 1179/1179 [03:44<00:00,  5.24it/s, Loss: 5.994 (4.758)]\n",
            "Train(6): 100%|██████████| 1179/1179 [03:44<00:00,  5.25it/s, Loss: 1.861 (4.488)]\n",
            "Train(7): 100%|██████████| 1179/1179 [03:45<00:00,  5.23it/s, Loss: 4.307 (4.244)]\n",
            "Train(8): 100%|██████████| 1179/1179 [03:45<00:00,  5.23it/s, Loss: 3.600 (4.002)]\n",
            "Train(9): 100%|██████████| 1179/1179 [03:44<00:00,  5.26it/s, Loss: 0.711 (3.777)]\n",
            "Train(10): 100%|██████████| 1179/1179 [03:45<00:00,  5.23it/s, Loss: 5.663 (3.570)]\n",
            "Train(11): 100%|██████████| 1179/1179 [03:46<00:00,  5.21it/s, Loss: 2.845 (3.353)]\n",
            "Train(12): 100%|██████████| 1179/1179 [03:47<00:00,  5.17it/s, Loss: 4.764 (3.150)]\n",
            "Train(13): 100%|██████████| 1179/1179 [03:48<00:00,  5.17it/s, Loss: 4.811 (2.952)]\n",
            "Train(14): 100%|██████████| 1179/1179 [03:49<00:00,  5.14it/s, Loss: 4.625 (2.758)]\n",
            "Train(15): 100%|██████████| 1179/1179 [03:46<00:00,  5.21it/s, Loss: 4.390 (2.570)]\n",
            "Train(16): 100%|██████████| 1179/1179 [03:51<00:00,  5.08it/s, Loss: 0.996 (2.389)]\n",
            "Train(17): 100%|██████████| 1179/1179 [03:49<00:00,  5.14it/s, Loss: 0.228 (2.217)]\n",
            "Train(18): 100%|██████████| 1179/1179 [03:47<00:00,  5.19it/s, Loss: 0.548 (2.052)]\n",
            "Train(19): 100%|██████████| 1179/1179 [03:47<00:00,  5.17it/s, Loss: 1.631 (1.881)]\n",
            "Train(20): 100%|██████████| 1179/1179 [03:48<00:00,  5.16it/s, Loss: 0.205 (1.734)]\n",
            "Train(21): 100%|██████████| 1179/1179 [03:43<00:00,  5.26it/s, Loss: 2.500 (1.581)]\n",
            "Train(22): 100%|██████████| 1179/1179 [03:44<00:00,  5.25it/s, Loss: 0.443 (1.444)]\n",
            "Train(23): 100%|██████████| 1179/1179 [03:41<00:00,  5.32it/s, Loss: 2.696 (1.315)]\n",
            "Train(24): 100%|██████████| 1179/1179 [03:47<00:00,  5.18it/s, Loss: 0.311 (1.177)]\n",
            "Train(25): 100%|██████████| 1179/1179 [03:42<00:00,  5.29it/s, Loss: 0.593 (1.063)]\n",
            "Train(26): 100%|██████████| 1179/1179 [03:44<00:00,  5.26it/s, Loss: 2.461 (0.951)]\n",
            "Train(27): 100%|██████████| 1179/1179 [03:45<00:00,  5.23it/s, Loss: 0.009 (0.852)]\n",
            "Train(28): 100%|██████████| 1179/1179 [03:43<00:00,  5.28it/s, Loss: 0.071 (0.752)]\n",
            "Train(29): 100%|██████████| 1179/1179 [03:48<00:00,  5.16it/s, Loss: 0.018 (0.658)]\n",
            "Train(30): 100%|██████████| 1179/1179 [03:46<00:00,  5.21it/s, Loss: 0.319 (0.581)]\n",
            "Train(31): 100%|██████████| 1179/1179 [03:48<00:00,  5.17it/s, Loss: 0.705 (0.508)]\n",
            "Train(32): 100%|██████████| 1179/1179 [03:42<00:00,  5.30it/s, Loss: 0.037 (0.436)]\n",
            "Train(33): 100%|██████████| 1179/1179 [03:48<00:00,  5.17it/s, Loss: 1.294 (0.380)]\n",
            "Train(34): 100%|██████████| 1179/1179 [03:49<00:00,  5.13it/s, Loss: 0.043 (0.322)]\n",
            "Train(35): 100%|██████████| 1179/1179 [03:46<00:00,  5.21it/s, Loss: 0.450 (0.273)]\n",
            "Train(36): 100%|██████████| 1179/1179 [03:46<00:00,  5.21it/s, Loss: 0.018 (0.231)]\n",
            "Train(37): 100%|██████████| 1179/1179 [03:49<00:00,  5.14it/s, Loss: 0.671 (0.194)]\n",
            "Train(38): 100%|██████████| 1179/1179 [03:48<00:00,  5.16it/s, Loss: 0.551 (0.168)]\n",
            "Train(39): 100%|██████████| 1179/1179 [03:47<00:00,  5.19it/s, Loss: 0.060 (0.136)]\n",
            "Train(40): 100%|██████████| 1179/1179 [03:46<00:00,  5.21it/s, Loss: 0.116 (0.113)]\n",
            "Train(41): 100%|██████████| 1179/1179 [03:42<00:00,  5.31it/s, Loss: 0.181 (0.101)]\n",
            "Train(42): 100%|██████████| 1179/1179 [03:42<00:00,  5.29it/s, Loss: 0.123 (0.086)]\n",
            "Train(43): 100%|██████████| 1179/1179 [03:48<00:00,  5.16it/s, Loss: 0.053 (0.065)]\n",
            "Train(44): 100%|██████████| 1179/1179 [03:49<00:00,  5.14it/s, Loss: 0.206 (0.054)]\n",
            "Train(45): 100%|██████████| 1179/1179 [03:48<00:00,  5.17it/s, Loss: 0.237 (0.050)]\n",
            "Train(46): 100%|██████████| 1179/1179 [03:47<00:00,  5.17it/s, Loss: 0.119 (0.036)]\n",
            "Train(47): 100%|██████████| 1179/1179 [03:46<00:00,  5.20it/s, Loss: 0.018 (0.036)]\n",
            "Train(48): 100%|██████████| 1179/1179 [03:47<00:00,  5.17it/s, Loss: 0.076 (0.027)]\n",
            "Train(49): 100%|██████████| 1179/1179 [03:45<00:00,  5.22it/s, Loss: 0.005 (0.024)]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.582916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.477502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.407147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.248615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.012939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.758283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.487804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.244143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.001725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.777458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.570481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.352779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.150139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.951772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2.758420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2.569663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.388671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2.217337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.052248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.881352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.733991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.580959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.444259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.315223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.177354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.063494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.950987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.851830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.752032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.658299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.580981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.507621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.436235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.379539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.321608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.273253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.230976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.194128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.168147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.135520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.113068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.100739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.086309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.064782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.054494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.050250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.036134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.036166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.026628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.023566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss\n",
              "0   5.582916\n",
              "1   5.477502\n",
              "2   5.407147\n",
              "3   5.248615\n",
              "4   5.012939\n",
              "5   4.758283\n",
              "6   4.487804\n",
              "7   4.244143\n",
              "8   4.001725\n",
              "9   3.777458\n",
              "10  3.570481\n",
              "11  3.352779\n",
              "12  3.150139\n",
              "13  2.951772\n",
              "14  2.758420\n",
              "15  2.569663\n",
              "16  2.388671\n",
              "17  2.217337\n",
              "18  2.052248\n",
              "19  1.881352\n",
              "20  1.733991\n",
              "21  1.580959\n",
              "22  1.444259\n",
              "23  1.315223\n",
              "24  1.177354\n",
              "25  1.063494\n",
              "26  0.950987\n",
              "27  0.851830\n",
              "28  0.752032\n",
              "29  0.658299\n",
              "30  0.580981\n",
              "31  0.507621\n",
              "32  0.436235\n",
              "33  0.379539\n",
              "34  0.321608\n",
              "35  0.273253\n",
              "36  0.230976\n",
              "37  0.194128\n",
              "38  0.168147\n",
              "39  0.135520\n",
              "40  0.113068\n",
              "41  0.100739\n",
              "42  0.086309\n",
              "43  0.064782\n",
              "44  0.054494\n",
              "45  0.050250\n",
              "46  0.036134\n",
              "47  0.036166\n",
              "48  0.026628\n",
              "49  0.023566"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSjh6tv2QtOz"
      },
      "source": [
        "* TEST\n",
        "  * 해당 부분은 train이 아닌 example에 해당"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nH1YnvkQsct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b13e617-95dd-4dbc-dfeb-6b5f85d66544"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "from model.kobert import KoBERTforSequenceClassfication, kobert_input\n",
        "from kobert_transformers import get_tokenizer\n",
        "\n",
        "def load_wellness_answer():\n",
        "  root_path = \"/content/drive/MyDrive/Colab Notebooks/buddy\"\n",
        "  category_path = f\"{root_path}/data/wellness_dialog_category.txt\"\n",
        "  answer_path = f\"{root_path}/data/wellness_dialog_answer.txt\"\n",
        "\n",
        "  c_f = open(category_path,'r')\n",
        "  a_f = open(answer_path,'r')\n",
        "\n",
        "  category_lines = c_f.readlines()\n",
        "  answer_lines = a_f.readlines()\n",
        "\n",
        "  category = {}\n",
        "  answer = {}\n",
        "  for line_num, line_data in enumerate(category_lines):\n",
        "    data = line_data.split('    ')\n",
        "    category[data[1][:-1]]=data[0]\n",
        "\n",
        "  for line_num, line_data in enumerate(answer_lines):\n",
        "    data = line_data.split('    ')\n",
        "    keys = answer.keys()\n",
        "    if(data[0] in keys):\n",
        "      answer[data[0]] += [data[1][:-1]]\n",
        "    else:\n",
        "      answer[data[0]] =[data[1][:-1]]\n",
        "\n",
        "  return category, answer\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  root_path = \"/content/drive/MyDrive/Colab Notebooks/buddy\"\n",
        "  checkpoint_path =f\"{root_path}/checkpoint\"\n",
        "  save_ckpt_path = f\"{checkpoint_path}/kobert-wellnesee-text-classification.pth\"\n",
        "\n",
        "  #답변과 카테고리 불러오기\n",
        "  category, answer = load_wellness_answer()\n",
        "\n",
        "  ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  device = torch.device(ctx)\n",
        "\n",
        "  # 저장한 Checkpoint 불러오기\n",
        "  checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
        "\n",
        "  model = KoBERTforSequenceClassfication()\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "  model.to(ctx)\n",
        "  model.eval()\n",
        "\n",
        "  tokenizer = get_tokenizer()\n",
        "\n",
        "  while 1:\n",
        "    sent = input('\\nQuestion: ') # '요즘 기분이 우울한 느낌이에요'\n",
        "    data = kobert_input(tokenizer, sent, device, 512)\n",
        "\n",
        "    if '종료' in sent:\n",
        "      break\n",
        "\n",
        "    output = model(**data)\n",
        "\n",
        "    logit = output[0]\n",
        "    softmax_logit = torch.softmax(logit,dim=-1)\n",
        "    softmax_logit = softmax_logit.squeeze()\n",
        "\n",
        "    max_index = torch.argmax(softmax_logit).item()\n",
        "    max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n",
        "\n",
        "    answer_list = answer[category[str(max_index)]]\n",
        "    answer_len= len(answer_list)-1\n",
        "    answer_index = random.randint(0,answer_len)\n",
        "    print(f'Answer: {answer_list[answer_index]}, index: {max_index}, softmax_value: {max_index_value}')\n",
        "    print('-'*50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question: 요즘 우울한 기분이에요.\n",
            "Answer: 우울함은 저절로 없어지기도 하지만 그렇지 않을 때도 있어요. 그럴 때는 전문가에게 도움을 요청하는 것도 좋은 방법이에요., index: 59, softmax_value: 0.9988963603973389\n",
            "--------------------------------------------------\n",
            "\n",
            "Question: 가슴이 답답해서 터질 것만 같아요.\n",
            "Answer: 신체적인 문제는 없나요? 아니면 혹시 힘든 일이 있으신가요?, index: 264, softmax_value: 0.996057391166687\n",
            "--------------------------------------------------\n",
            "\n",
            "Question: 종료해주세요.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}